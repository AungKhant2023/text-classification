{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8baf75c1",
      "metadata": {
        "id": "8baf75c1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, Layer, Dense, Dropout, MultiHeadAttention, LayerNormalization, Input, GlobalAveragePooling1D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uKyYtPBnofsb",
        "outputId": "5e043e69-98ea-4e1f-e32c-1d76689def0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uKyYtPBnofsb",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/fine_tune_dataset.csv\",encoding='utf-8')"
      ],
      "metadata": {
        "id": "SqPmiSVB6JOv"
      },
      "id": "SqPmiSVB6JOv",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4345270e",
      "metadata": {
        "id": "4345270e",
        "outputId": "b347f1e8-4848-4bb2-f14a-e4f6611e84b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.remove('not')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "class MyanmarTextPreprocessor():\n",
        "    def __init__(self, dict_path: str, stop_path: str):\n",
        "        self.dictionary = self.load_dictionary(dict_path)\n",
        "        self.stopwords = self.load_stopwords(stop_path)\n",
        "\n",
        "    # Load dictionary into a set\n",
        "    def load_dictionary(self, dict_path):\n",
        "        dictionary = set()\n",
        "        with open(dict_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                word = line.strip()\n",
        "                if word:\n",
        "                    dictionary.add(word)\n",
        "        return dictionary\n",
        "\n",
        "    # Load stopwords into a set\n",
        "    def load_stopwords(self, stopword_path):\n",
        "        stopwords = set()\n",
        "        with open(stopword_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                word = line.strip()\n",
        "                if word:\n",
        "                    stopwords.add(word)\n",
        "        return stopwords\n",
        "\n",
        "    # Merge syllables based on dictionary\n",
        "    def merge_with_dictionary(self, syllables):\n",
        "        merged_tokens = []\n",
        "        i = 0\n",
        "        while i < len(syllables):\n",
        "            matched = False\n",
        "            for j in range(len(syllables), i, -1):\n",
        "                combined = ''.join(syllables[i:j])\n",
        "                if combined in self.dictionary:\n",
        "                    merged_tokens.append(combined)\n",
        "                    i = j\n",
        "                    matched = True\n",
        "                    break\n",
        "            if not matched:\n",
        "                merged_tokens.append(syllables[i])\n",
        "                i += 1\n",
        "        return merged_tokens\n",
        "\n",
        "    def preprocessing(self, text: str):\n",
        "        text = re.sub(r\"(([A-Za-z0-9]+)|[က-အ|ဥ|ဦ](င်္|[က-အ][ှ]*[့း]*[်]|္[က-အ]|[ါ-ှႏꩻ][ꩻ]*){0,}|.)\", r\"\\1 \", text)\n",
        "        text = text.strip().split()\n",
        "        merged_tokens = self.merge_with_dictionary(text)\n",
        "        filtered_tokens = [token for token in merged_tokens if token not in self.stopwords]\n",
        "        return ' '.join(filtered_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = MyanmarTextPreprocessor('/content/drive/MyDrive/Datasets/dict-words.txt', '/content/drive/MyDrive/Datasets/sw.txt')\n"
      ],
      "metadata": {
        "id": "BIyl1TtTnWPR"
      },
      "id": "BIyl1TtTnWPR",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df['Sentence']\n",
        "label = df['Label']\n",
        "X_train, X_val, y_train, y_val = train_test_split(sentences, label, test_size=0.2, stratify=label, random_state=40)"
      ],
      "metadata": {
        "id": "Ir6KTCpwiP6N"
      },
      "id": "Ir6KTCpwiP6N",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_clean = X_train.apply(preprocessor.preprocessing)\n",
        "X_val_clean = X_val.apply(preprocessor.preprocessing)"
      ],
      "metadata": {
        "id": "Opuy2iCtiTC6"
      },
      "id": "Opuy2iCtiTC6",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overlap = set(X_train_clean).intersection(set(X_val_clean))\n",
        "print(f\"Number of overlapping samples: {len(overlap)}\")\n",
        "X_val_clean = [x for x in X_val_clean if x not in X_train_clean]"
      ],
      "metadata": {
        "id": "1QuU5M4CiWfs",
        "outputId": "8934850a-21bf-403c-816c-cda0376a76d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1QuU5M4CiWfs",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of overlapping samples: 470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_label = {\n",
        "    'Social': 0,\n",
        "    'Entertainment': 1,\n",
        "    'Product&Service': 2,\n",
        "    'Business': 3,\n",
        "    'Sports': 4,\n",
        "    'Science&Technology': 5,\n",
        "    'Education': 6,\n",
        "    'Culture&History': 7,\n",
        "    'Health': 8,\n",
        "    'Environmental': 9,\n",
        "    'Political': 10,\n",
        "    'Gambling': 11,\n",
        "    'Adult Content': 12,\n",
        "}\n",
        "y_train_encoded = y_train.map(map_label)\n",
        "y_val_encoded = y_val.map(map_label)"
      ],
      "metadata": {
        "id": "-f8pnQwZjMXC"
      },
      "id": "-f8pnQwZjMXC",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, heads, neurons, dropout_rate=0.5,**kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.att = layers.MultiHeadAttention(num_heads=heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([\n",
        "            layers.Dense(neurons, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=False):\n",
        "        # Multi-head self-attention with mask\n",
        "        attn_output = self.att(inputs, inputs, attention_mask=mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Token + Position Embedding\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim,**kwargs):\n",
        "        super(TokenAndPositionEmbedding, self).__init__(**kwargs)\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "G0m5kvEhni_v"
      },
      "id": "G0m5kvEhni_v",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/Datasets/my_transformer_model_1.h5', custom_objects={\n",
        "    'TransformerEncoder': TransformerEncoder,\n",
        "    'TokenAndPositionEmbedding': TokenAndPositionEmbedding,\n",
        "})\n",
        "with open('/content/drive/MyDrive/Datasets/tokenizer_1.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_clean)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val_clean)\n",
        "\n",
        "MAX_LEN = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "oocTquVSnufj",
        "outputId": "4fc08589-889b-4360-c258-3e7b97835252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oocTquVSnufj",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.00003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kM4rVeny87fy",
        "outputId": "8be0adb1-1887-42ea-f6dd-4a9851e60774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "id": "kM4rVeny87fy",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │ \u001b[38;5;34m12,240,300\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │  \u001b[38;5;34m1,464,632\u001b[0m │ token_and_positi… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)        │      \u001b[38;5;34m3,913\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,240,300</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464,632</span> │ token_and_positi… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,913</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,708,845\u001b[0m (52.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,708,845</span> (52.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,708,845\u001b[0m (52.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,708,845</span> (52.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor = \"val_loss\",min_delta = 0.0001,patience = 4,verbose = 1)\n",
        "history = model.fit(X_train_pad,y_train_encoded,\n",
        "                    validation_data=(X_val_pad,y_val_encoded),\n",
        "                    epochs=25,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Htx_avsirebf",
        "outputId": "c9eef156-985e-42e7-a756-962df2169c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Htx_avsirebf",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 254ms/step - accuracy: 0.8369 - loss: 0.5697 - val_accuracy: 0.8803 - val_loss: 0.4068\n",
            "Epoch 2/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 245ms/step - accuracy: 0.8996 - loss: 0.3284 - val_accuracy: 0.8940 - val_loss: 0.3677\n",
            "Epoch 3/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 245ms/step - accuracy: 0.9292 - loss: 0.2332 - val_accuracy: 0.8987 - val_loss: 0.3650\n",
            "Epoch 4/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 245ms/step - accuracy: 0.9494 - loss: 0.1660 - val_accuracy: 0.9048 - val_loss: 0.3541\n",
            "Epoch 5/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 245ms/step - accuracy: 0.9638 - loss: 0.1238 - val_accuracy: 0.9023 - val_loss: 0.3642\n",
            "Epoch 6/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 247ms/step - accuracy: 0.9726 - loss: 0.0949 - val_accuracy: 0.9048 - val_loss: 0.3830\n",
            "Epoch 7/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 252ms/step - accuracy: 0.9816 - loss: 0.0658 - val_accuracy: 0.9067 - val_loss: 0.4032\n",
            "Epoch 8/25\n",
            "\u001b[1m1617/1617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 251ms/step - accuracy: 0.9871 - loss: 0.0482 - val_accuracy: 0.9014 - val_loss: 0.4409\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(X_val_pad, y_val_encoded, batch_size=32)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "CJUdhp-Srmcy",
        "outputId": "b7da1fed-b217-4ec2-bf4a-7caa8f3a6540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CJUdhp-Srmcy",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m  3/405\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.8663 - loss: 0.5665"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.8965 - loss: 0.4674\n",
            "Validation Accuracy: 0.9014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred_prob = model.predict(X_val_pad)          # Predict probabilities\n",
        "y_pred = y_pred_prob.argmax(axis=1)             # Convert to predicted class indices\n",
        "y_true = y_val_encoded\n",
        "print(classification_report(y_true, y_pred, digits=4))"
      ],
      "metadata": {
        "id": "YKIWaF4hrpYM",
        "outputId": "4a8185b2-c7c0-428c-9a5d-e25295933c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YKIWaF4hrpYM",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8311    0.6150    0.7069      1000\n",
            "           1     0.8420    0.9060    0.8728      1000\n",
            "           2     0.8707    0.8620    0.8663      1000\n",
            "           3     0.9333    0.8820    0.9069      1000\n",
            "           4     0.9620    0.9360    0.9488      1000\n",
            "           5     0.7910    0.8970    0.8407      1000\n",
            "           6     0.9182    0.9650    0.9410      1000\n",
            "           7     0.8721    0.9140    0.8926      1000\n",
            "           8     0.9348    0.9170    0.9258      1000\n",
            "           9     0.9432    0.9300    0.9366      1000\n",
            "          10     0.9049    0.9520    0.9279      1000\n",
            "          11     0.9707    0.9582    0.9644       932\n",
            "          12     0.9537    0.9880    0.9705      1000\n",
            "\n",
            "    accuracy                         0.9014     12932\n",
            "   macro avg     0.9021    0.9017    0.9001     12932\n",
            "weighted avg     0.9018    0.9014    0.8998     12932\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('finetune_transformer_ver1.2.keras')\n",
        "with open('finetune_tokenizer_ver1.2.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "0DKHqaTLbD6r"
      },
      "id": "0DKHqaTLbD6r",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('finetune_transformer_ver1.2.keras')"
      ],
      "metadata": {
        "id": "gTIfB9FyLA4V",
        "outputId": "66640166-98be-4964-fc70-b0da5152ed2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "gTIfB9FyLA4V",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_46f1eebc-e4fd-4600-b88d-27d8eaa0792d\", \"finetune_transformer_ver1.2.keras\", 164586328)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rji056fdLIo-"
      },
      "id": "Rji056fdLIo-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}